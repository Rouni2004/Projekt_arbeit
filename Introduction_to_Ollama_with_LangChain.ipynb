{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to use Ollama in a Jupyter Notebook\n",
    "- Use vpn server \"vpn.hiz-saarland.de\" (https://www.hiz-saarland.de/dienste/vpn/)\n",
    "- http://134.96.217.20:53100/api/tags lists available models on our server\n",
    "- Go to [Ollama](https://ollama.com/) and check out the models that are available\n",
    "- Try out different models\n",
    "- Try out different parameters and get to know what they do: https://github.com/ollama/ollama/blob/main/docs/api.md#parameters"
   ],
   "id": "b34b1972783c5a0"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T10:53:24.226782Z",
     "start_time": "2025-04-25T10:53:18.465201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    base_url=\"http://134.96.217.20:53100\",      # or soon http://134.96.217.20:53101\n",
    "    model=\"gemma:7b\",                         # or gemma:7b or llama3-70b or mistral-7b ...\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=20,\n",
    "    repeat_penalty=1.2,\n",
    "    presence_penalty=1.5\n",
    "    )\n",
    "\n",
    "response = llm.invoke(\"Why is the sky blue?\")\n",
    "print(response)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sky appears Blue due to a phenomenon called **Rayleigh Scattering**.\n",
      "\n",
      "- Sunlight consists of all colors in visible spectrum.\n",
      "\n",
      "\n",
      "**When sunlight interacts with molecules like Nitrogen and Oxygen present air:**  These particles are much smaller than wavelength if light they scatter the waves randomly, but because these scattering events conserve energy momentum direction matters more for scattered wave's intensity \n",
      "* Shorter wavelengths (blue/violet) tend to be deflected in many different directions resulting less intense overall compared with longer Wavelength(red).\n",
      "\n",
      "\n",
      "- As a result of this selective Scattering:  **Blue light is dispersed throughout the sky, reaching our eyes from every angle**.\n",
      "\n",
      "Therefore we see mostly Blue Sky during clear weather.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Learn Langchain\n",
    "- What is LangChain?\n",
    "- What are its key components?"
   ],
   "id": "3da04f0318a5c075"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt Template\n",
    "- What is it? Why and How is it used?\n",
    "- Template with multiple inputs?\n",
    "- How do you handle a conversation history?\n",
    "- What are these prompt engineering techniques?\n",
    "    - **Zero-Shot Prompting**\n",
    "    - **Role Prompting**\n",
    "    - **Chain-of-Thought Prompting (CoT)**\n",
    "    - What are important things to consider?"
   ],
   "id": "9620a1ff09d92f14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:53:30.799236Z",
     "start_time": "2025-04-25T10:53:30.792918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_kids = PromptTemplate(\n",
    "    input_variables=[\"frage\"],\n",
    "    template=(\n",
    "        \"Du bist ein freundlicher Assistent, der Kindern auf ihre Fragen antwortet.\\n\"\n",
    "        \"Erkläre Dinge in einfacher, kindgerechter Sprache, damit Kinder im Alter von 6 bis 10 Jahren sie gut verstehen können.\\n\"\n",
    "        \"Sei positiv, ermutigend und benutze kurze, klare Sätze.\\n\"\n",
    "        \"Wenn es passt, darfst du Beispiele oder kleine Vergleiche verwenden, damit es noch besser verständlich wird.\\n\\n\"\n",
    "        \"Frage: {frage}\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    ")"
   ],
   "id": "59fce3165420973b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:11:28.119553Z",
     "start_time": "2025-04-25T10:11:28.113311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template_medical = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"Du bist ein medizinischer Assistent. \"\n",
    "        \"Du gibst sachliche, evidenzbasierte Informationen zu medizinischen Fragen. \"\n",
    "        \"Du gibst keine Diagnosen und ersetzt keinen ärztlichen Rat. \"\n",
    "        \"Verweise bei Bedarf darauf, dass Patient:innen eine Ärztin oder einen Arzt aufsuchen sollten.\"\n",
    "    )),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ],
   "id": "f718736c23c4f012",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combine Template with your LLM\n",
    "- How can I customize the chain and use my own coded python functions?\n",
    "- What are common steps in a llm chain?"
   ],
   "id": "a42ab6834dff40ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:53:33.498364Z",
     "start_time": "2025-04-25T10:53:32.544109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = (\n",
    "        template_kids  # Format messages into structured chat format\n",
    "        | llm\n",
    ")\n",
    "\n",
    "chain.invoke(\"Warum können Fische unter Wasser atmen?\")"
   ],
   "id": "54e8503b81e70bb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fische haben eine besondere Luftblase im Bauch genannt \"Swimbladder\", die ihnen hilft zuAtmen! Diese Blase ist wie ein Schwimmer und hält den Fisch mit dem Kopf nach oben. So kann er durch dasWasser gehen, ohne dass ihm der Sauerstoff ausläuft!\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Output Parsers\n",
    "Sometimes a model's response is free text, but you need:\n",
    "- A specific format (like JSON)\n",
    "- Only part of the answer (e.g. just the code)\n",
    "\n",
    "### Questions:\n",
    "- What is an output parser in LangChain?\n",
    "- How do I use it to extract structured information?\n",
    "- How can I convert the LLM response to a JSON object?\n",
    "- How do I add them to the chain?"
   ],
   "id": "293a37c574b2ce7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Explore and have fun",
   "id": "a849c62c2b82ed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## More\n",
    "- You will need more components and probably also other python packages for your project.\n",
    "- No problem you will learn how to use it."
   ],
   "id": "7a06d807c6df89ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLMs in General\n",
    "These are important background topics to include in your project or thesis.\n",
    "You don’t need to cover all in detail, but you should show awareness of them:\n",
    "\n",
    "- What is a **Large Language Model (LLM)**?\n",
    "- What are **hallucinations** and **bias**?\n",
    "- What risks and ethical questions do LLMs raise?\n",
    "- What kinds of **LLM architectures** exist?\n",
    "- What is the Transformer architecture? What is attention?\n",
    "- What’s the difference between **proprietary**, **open**, and **open-source** models?\n",
    "- What are typical applications and use cases for LLMs?"
   ],
   "id": "2c1d0ee1446f25c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
