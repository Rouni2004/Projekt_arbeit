{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Der alte code",
   "id": "d898571d5339bad5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:49:49.165645Z",
     "start_time": "2025-06-02T12:49:10.296379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# === XML-Dateien einlesen ===\n",
    "xml_files = [\"moduldb-pi2.xml\", \"Modulbook_pi2_de.xml\"]\n",
    "docs = []\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        xml_content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(xml_content, \"xml\")\n",
    "    modules = soup.find_all(\"moduleheader\")\n",
    "\n",
    "    for module in modules:\n",
    "        title = module.find(\"title\").text.strip() if module.find(\"title\") else \"Kein Titel\"\n",
    "        cid = module.find(\"cid\").text.strip() if module.find(\"cid\") else \"Kein K√ºrzel\"\n",
    "        cp = module.find(\"cp\").text.strip() if module.find(\"cp\") else \"?\"\n",
    "        convenor = module.find(\"convenor\").text.strip() if module.find(\"convenor\") else \"?\"\n",
    "\n",
    "        types = module.find_all(\"type\")\n",
    "        ctypes = \", \".join(t.text for t in types) if types else \"Unbekannt\"\n",
    "\n",
    "        content = f\"\"\"\n",
    "Modul: {title}\n",
    "K√ºrzel: {cid}\n",
    "Leistungspunkte (ECTS): {cp}\n",
    "Verantwortlich: {convenor}\n",
    "Veranstaltungstyp(en): {ctypes}\n",
    "\"\"\"\n",
    "        docs.append(Document(page_content=content.strip()))\n",
    "\n",
    "# Debug: Beispielinhalt zeigen\n",
    "if docs:\n",
    "    print(\"üìÑ Beispiel-Inhalt:\\n\", docs[0].page_content[:500])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Keine Module gefunden.\")\n",
    "\n",
    "# === Dokumente splitten ===\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# === Embeddings & Chroma ===\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "# === LLM √ºber Ollama (Server) ===\n",
    "llm = OllamaLLM(\n",
    "    base_url=\"http://134.96.217.20:53100\",\n",
    "    model=\"llama3-70b\",\n",
    "    temperature=0.5,\n",
    "    top_p=0.8,\n",
    "    top_k=10,\n",
    "    repeat_penalty=1.1,\n",
    "    presence_penalty=1.2\n",
    ")\n",
    "\n",
    "# === Prompt ===\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Hier ist ein Auszug aus Moduldaten:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Beantworte bitte diese Frage auf einfache Weise:\\n\"\n",
    "        \"{question}\\n\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# === QA-Kette ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# === Chat starten ===\n",
    "print(\"ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\\n\")\n",
    "while True:\n",
    "    user_input = input(\"Du: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ü§ñ Bot: Auf Wiedersehen!\")\n",
    "        break\n",
    "    try:\n",
    "        response = qa_chain.run(user_input)\n",
    "        print(\"ü§ñ Bot:\", response)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Fehler: {e}\")"
   ],
   "id": "b8a0a4db83fd0d37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Beispiel-Inhalt:\n",
      " Modul: Bachelor-Abschlussarbeit\n",
      "K√ºrzel: PIB-BT\n",
      "Leistungspunkte (ECTS): 12\n",
      "Verantwortlich: Studienleitung\n",
      "Veranstaltungstyp(en): Unbekannt\n",
      "ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\n",
      "\n",
      "ü§ñ Bot: Das Fach \"Informatik 1\" hat 5 ECTS-Leistungspunkte.\n",
      "ü§ñ Bot: Auf Wiedersehen!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Der neue Code",
   "id": "71bc7185fe938f61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:18:33.995193Z",
     "start_time": "2025-06-02T13:17:53.487382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# === Inhalte.txt laden ===\n",
    "docs = []\n",
    "with open(\"Inhalte.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "blocks = content.split(\"============================================================\")\n",
    "for block in blocks:\n",
    "    block = block.strip()\n",
    "    if len(block) > 100:\n",
    "        docs.append(Document(page_content=block))\n",
    "\n",
    "print(f\"üìÑ Datei 'Inhalte.txt' geladen. Module erkannt: {len(docs)}\")\n",
    "\n",
    "# === In kleinere Chunks aufteilen (wenn n√∂tig) ===\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# === Vektordatenbank mit Embeddings aufbauen ===\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# === LLM konfigurieren ===\n",
    "llm = OllamaLLM(\n",
    "    base_url=\"http://134.96.217.20:53100\",  # ggf. deine Adresse\n",
    "    model=\"llama3-70b\",  # oder mistral-7b je nach ollama setup\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# === Prompt definieren ===\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Hier ist ein Auszug aus Modulbeschreibungen:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Beantworte die folgende Frage **nur auf Basis dieser Informationen**. \"\n",
    "        \"Wenn die Antwort nicht im Text steht, sage: 'Nicht enthalten'.\\n\\n\"\n",
    "        \"Frage: {question}\\n\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# === Retrieval-QA-Kette starten ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# === Chat starten ===\n",
    "print(\"\\nü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\\n\")\n",
    "while True:\n",
    "    user_input = input(\"Du: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ü§ñ Bot: Auf Wiedersehen!\")\n",
    "        break\n",
    "    try:\n",
    "        response = qa_chain.run(user_input)\n",
    "        print(\"ü§ñ Bot:\", response)\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Fehler:\", e)\n"
   ],
   "id": "41d5551067243954",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Datei 'Inhalte.txt' geladen. Module erkannt: 3\n",
      "\n",
      "ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\n",
      "\n",
      "ü§ñ Bot: Die Fragen k√∂nnen wie folgt beantwortet werden:\n",
      "\n",
      "1. Was sind die Lernziele im Modul Betriebswirtschaftslehre?\n",
      "   - Nicht enthalten.\n",
      "\n",
      "2. Welche Inhalte hat Business Comm. and Intercultural Competence?\n",
      "   - Die spezifischen Inhalte des Moduls \"Business Communication and Intercultural Competence\" werden nicht genannt, aber es verwendet Lehrmethoden wie √úbungen, Fallstudien und Gamification. Die Literatur bezieht sich jedoch auf Betriebswirtschaftslehre.\n",
      "\n",
      "3. Was lernt man in Betriebssystemeinf√ºhrung?\n",
      "   - Nicht enthalten. Es gibt keine Informationen √ºber ein Modul namens \"Betriebssystemeinf√ºhrung\".\n",
      "\n",
      "4. Wie viele ECTS hat das Modul PIB-BWL?\n",
      "   - 5 ECTS-Punkte.\n",
      "ü§ñ Bot: Auf Wiedersehen!\n"
     ]
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
