{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Der alte code",
   "id": "d898571d5339bad5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:49:49.165645Z",
     "start_time": "2025-06-02T12:49:10.296379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# === XML-Dateien einlesen ===\n",
    "xml_files = [\"moduldb-pi2.xml\", \"Modulbook_pi2_de.xml\"]\n",
    "docs = []\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        xml_content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(xml_content, \"xml\")\n",
    "    modules = soup.find_all(\"moduleheader\")\n",
    "\n",
    "    for module in modules:\n",
    "        title = module.find(\"title\").text.strip() if module.find(\"title\") else \"Kein Titel\"\n",
    "        cid = module.find(\"cid\").text.strip() if module.find(\"cid\") else \"Kein K√ºrzel\"\n",
    "        cp = module.find(\"cp\").text.strip() if module.find(\"cp\") else \"?\"\n",
    "        convenor = module.find(\"convenor\").text.strip() if module.find(\"convenor\") else \"?\"\n",
    "\n",
    "        types = module.find_all(\"type\")\n",
    "        ctypes = \", \".join(t.text for t in types) if types else \"Unbekannt\"\n",
    "\n",
    "        content = f\"\"\"\n",
    "Modul: {title}\n",
    "K√ºrzel: {cid}\n",
    "Leistungspunkte (ECTS): {cp}\n",
    "Verantwortlich: {convenor}\n",
    "Veranstaltungstyp(en): {ctypes}\n",
    "\"\"\"\n",
    "        docs.append(Document(page_content=content.strip()))\n",
    "\n",
    "# Debug: Beispielinhalt zeigen\n",
    "if docs:\n",
    "    print(\"üìÑ Beispiel-Inhalt:\\n\", docs[0].page_content[:500])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Keine Module gefunden.\")\n",
    "\n",
    "# === Dokumente splitten ===\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# === Embeddings & Chroma ===\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "# === LLM √ºber Ollama (Server) ===\n",
    "llm = OllamaLLM(\n",
    "    base_url=\"http://134.96.217.20:53100\",\n",
    "    model=\"llama3-70b\",\n",
    "    temperature=0.5,\n",
    "    top_p=0.8,\n",
    "    top_k=10,\n",
    "    repeat_penalty=1.1,\n",
    "    presence_penalty=1.2\n",
    ")\n",
    "\n",
    "# === Prompt ===\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Hier ist ein Auszug aus Moduldaten:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Beantworte bitte diese Frage auf einfache Weise:\\n\"\n",
    "        \"{question}\\n\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# === QA-Kette ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# === Chat starten ===\n",
    "print(\"ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\\n\")\n",
    "while True:\n",
    "    user_input = input(\"Du: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ü§ñ Bot: Auf Wiedersehen!\")\n",
    "        break\n",
    "    try:\n",
    "        response = qa_chain.run(user_input)\n",
    "        print(\"ü§ñ Bot:\", response)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Fehler: {e}\")"
   ],
   "id": "b8a0a4db83fd0d37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Beispiel-Inhalt:\n",
      " Modul: Bachelor-Abschlussarbeit\n",
      "K√ºrzel: PIB-BT\n",
      "Leistungspunkte (ECTS): 12\n",
      "Verantwortlich: Studienleitung\n",
      "Veranstaltungstyp(en): Unbekannt\n",
      "ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\n",
      "\n",
      "ü§ñ Bot: Das Fach \"Informatik 1\" hat 5 ECTS-Leistungspunkte.\n",
      "ü§ñ Bot: Auf Wiedersehen!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Der neue Code",
   "id": "71bc7185fe938f61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:35:26.010447Z",
     "start_time": "2025-06-24T10:34:19.896290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Einlesen der Daten und Definition Chatbot\n",
    "\n",
    "# Import von langchain-Komponenten und externen Tools\n",
    "from langchain.docstore.document import Document  # Datenstruktur f√ºr Dokumente\n",
    "from langchain.prompts import PromptTemplate  # F√ºr benutzerdefinierte Prompts\n",
    "from langchain.chains import RetrievalQA  # Frage-Antwort-Kette auf Basis von Retrieval\n",
    "from langchain_community.vectorstores import Chroma  # Vektor-Datenbank (Chroma)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Text-Splitter f√ºr Chunking\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # Embedding-Modell von HuggingFace\n",
    "from langchain_ollama import OllamaLLM  # Lokales Ollama-LLM\n",
    "from bs4 import BeautifulSoup  # F√ºr XML-Parsing\n",
    "\n",
    "# === Inhalte.txt laden ===\n",
    "docs = []  # Liste f√ºr Hauptdokumente\n",
    "chunks = []  # Liste f√ºr vorbereitete Text-Chunks\n",
    "\n",
    "# Inhalte.txt vollst√§ndig einlesen\n",
    "with open(\"Inhalte.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Aufteilen in einzelne Modulbl√∂cke\n",
    "blocks = content.split(\"============================================================\")\n",
    "for block in blocks:\n",
    "    block = block.strip()\n",
    "    if len(block) > 100:  # Filter f√ºr leere oder zu kleine Bl√∂cke\n",
    "        docs.append(Document(page_content=block))\n",
    "\n",
    "print(f\"üìÑ Datei 'Inhalte.txt' geladen. Module erkannt: {len(docs)}\")\n",
    "\n",
    "# === Chunking vorbereiten ===\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=60)\n",
    "\n",
    "# Manual chunking mit Modulnamen zur Orientierung\n",
    "for doc in docs:\n",
    "    first_line = doc.page_content.split(\"\\n\")[0]  # z.B. \"Modul: Betriebssystemeinf√ºhrung\"\n",
    "    vorlesung = first_line.split(\":\", 1)[1].strip().upper()\n",
    "    for chunk_text in splitter.split_text(doc.page_content):\n",
    "        full_chunk = f\"{vorlesung}\\n{chunk_text}\\n{vorlesung}\"  # Modulname oben & unten f√ºr Kontext\n",
    "        chunks.append(Document(\n",
    "            page_content=full_chunk,\n",
    "            metadata={\"modul\": vorlesung.lower()}  # kann sp√§ter f√ºr gezielte Filterung verwendet werden\n",
    "        ))\n",
    "\n",
    "# === XML-Dateien einlesen ===\n",
    "xml_files = [\"moduldb-pi2.xml\", \"modulbook_pi2_de.xml\"]\n",
    "docs = []  # XML-Daten √ºberschreiben hier absichtlich vorherige docs-Liste\n",
    "\n",
    "# XML parsen mit BeautifulSoup\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        xml_content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(xml_content, \"xml\")\n",
    "    modules = soup.find_all(\"moduleheader\")  # Module sind unter <moduleheader> gelistet\n",
    "\n",
    "    for module in modules:\n",
    "        # Extraktion typischer Felder aus dem Modul\n",
    "        title = module.find(\"title\").text.strip() if module.find(\"title\") else \"Kein Titel\"\n",
    "        cid = module.find(\"cid\").text.strip() if module.find(\"cid\") else \"Kein K√ºrzel\"\n",
    "        cp = module.find(\"cp\").text.strip() if module.find(\"cp\") else \"?\"\n",
    "        convenor = module.find(\"convenor\").text.strip() if module.find(\"convenor\") else \"?\"\n",
    "\n",
    "        types = module.find_all(\"type\")\n",
    "        ctypes = \", \".join(t.text for t in types) if types else \"Unbekannt\"\n",
    "\n",
    "        content = f\"\"\"\n",
    "Modul: {title}\n",
    "K√ºrzel: {cid}\n",
    "Leistungspunkte (ECTS): {cp}\n",
    "Verantwortlich: {convenor}\n",
    "Veranstaltungstyp(en): {ctypes}\n",
    "\"\"\"\n",
    "        docs.append(Document(page_content=content.strip()))  # Wieder als LangChain-Dokument speichern\n",
    "\n",
    "print(f\"{len(docs)} Dokumente aus xml Dateien extrahiert.\")\n",
    "\n",
    "# XML-Daten auch als Chunks splitten und hinzuf√ºgen\n",
    "chunks.extend(splitter.split_documents(docs))\n",
    "\n",
    "# === Vektordatenbank aufbauen ===\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"multi-qa-mpnet-base-dot-v1\")  # Hochwertiges QA-Embedding-Modell\n",
    "db = Chroma.from_documents(chunks, embeddings)  # Chroma-Vektordatenbank aufbauen\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 7})  # Suche nach den 7 √§hnlichsten Chunks\n",
    "\n",
    "# === LLM starten ===\n",
    "llm = OllamaLLM(\n",
    "    base_url=\"http://134.96.217.20:53100\",  # Ollama API-Adresse\n",
    "    model=\"llama3-70b\",  # Verwendetes Modell\n",
    "    temperature=0.3  # Kreativit√§t / Zuf√§lligkeit der Antwort\n",
    ")\n",
    "\n",
    "# === Prompt f√ºr Frage-Antwort-System ===\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Hier ist ein Auszug aus Modulbeschreibungen:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Beantworte die folgende Frage **nur auf Basis dieser Informationen**. \"\n",
    "        \"Wenn die Antwort nicht im Text steht, sage: 'Nicht enthalten'.\\n\\n\"\n",
    "        \"Frage: {question}\\n\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# === QA-Kette starten ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",  # alle Chunks \"stuffed\" in ein Prompt\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "## Run Chatbot\n",
    "# === Interaktive Schleife ===\n",
    "print(\"\\nü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\\n\")\n",
    "while True:\n",
    "    user_input = input(\"Du: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ü§ñ Bot: Auf Wiedersehen!\")\n",
    "        break\n",
    "    try:\n",
    "        response = qa_chain.invoke({\"query\": user_input})  # Achtung: invoke braucht {\"query\": ...}\n",
    "        print(\"ü§ñ Bot:\", response[\"result\"])  # Zeigt nur den Antworttext\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Fehler:\", e)\n",
    "\n",
    "## Test\n",
    "# Einzelne Testabfrage (nicht interaktiv)\n",
    "retriever.invoke(\"Literatur Betriebssystemeinf√ºhrung?\")  # Ruft relevante Chunks ab (kein LLM)\n"
   ],
   "id": "36a9ea3a40e93bf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Datei 'Inhalte.txt' geladen. Module erkannt: 30\n",
      "121 Dokumente aus xml Dateien extrahiert.\n",
      "\n",
      "ü§ñ Chatbot gestartet! Tipp 'exit' oder 'quit' zum Beenden.\n",
      "\n",
      "ü§ñ Bot: Prof. Dr. Peter Birkner\n",
      "ü§ñ Bot: Auf Wiedersehen!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'modul': 'betriebswirtschaftslehre'}, page_content='BETRIEBSWIRTSCHAFTSLEHRE\\nLiteratur:\\n- Jean-Paul Thommen, Ann-Kristin Achleitner: *Allgemeine Betriebswirtschaftslehre*, Springer\\n- Thomas Straub: *Einf√ºhrung in die Allgemeine Betriebswirtschaftslehre*, Pearson\\n- Henner Schierenbeck, Claudia W√∂hle: *Grundz√ºge der Betriebswirtschaftslehre*, Oldenbourg\\n- Han\\nBETRIEBSWIRTSCHAFTSLEHRE'),\n",
       " Document(metadata={'modul': 'betriebswirtschaftslehre'}, page_content='BETRIEBSWIRTSCHAFTSLEHRE\\nLiteratur:\\n- Jean-Paul Thommen, Ann-Kristin Achleitner: *Allgemeine Betriebswirtschaftslehre*, Springer\\n- Thomas Straub: *Einf√ºhrung in die Allgemeine Betriebswirtschaftslehre*, Pearson\\n- Henner Schierenbeck, Claudia W√∂hle: *Grundz√ºge der Betriebswirtschaftslehre*, Oldenbourg\\n- Han\\nBETRIEBSWIRTSCHAFTSLEHRE'),\n",
       " Document(metadata={'modul': 'betriebssysteme'}, page_content='BETRIEBSSYSTEME\\nLiteratur:\\n- J. Nehmer, P. Sturm: Systemsoftware ‚Äì Grundlagen moderner Betriebssysteme, Punkt, 2001\\n- A. Tanenbaum, H. Bos: Moderne Betriebssysteme, Pearson Studium, 2016\\n- W. Stallings: Operating Systems, Prentice Hall, 2014\\n- A. Silberschatz et al.: Operating System Concepts, Wiley, 2008\\n\\nAngeboten in folgenden Semestern:\\nSS 2025, SS 2024, SS 2023, SS 2022, SS 2021\\nBETRIEBSSYSTEME'),\n",
       " Document(metadata={'modul': 'betriebssysteme'}, page_content='BETRIEBSSYSTEME\\nLiteratur:\\n- J. Nehmer, P. Sturm: Systemsoftware ‚Äì Grundlagen moderner Betriebssysteme, Punkt, 2001\\n- A. Tanenbaum, H. Bos: Moderne Betriebssysteme, Pearson Studium, 2016\\n- W. Stallings: Operating Systems, Prentice Hall, 2014\\n- A. Silberschatz et al.: Operating System Concepts, Wiley, 2008\\n\\nAngeboten in folgenden Semestern:\\nSS 2025, SS 2024, SS 2023, SS 2022, SS 2021\\nBETRIEBSSYSTEME'),\n",
       " Document(metadata={'modul': 'betriebssystemeinf√ºhrung'}, page_content='BETRIEBSSYSTEMEINF√úHRUNG\\nLiteratur:\\n- Powers, Peek, O‚ÄôReilly, Loukides: *Unix Power Tools*, O‚ÄôReilly, 2002\\n- Rosenblatt: *Learning the Korn Shell*, O‚ÄôReilly, 1995\\n- Stapelberg: *UNIX SYSTEM V.4*, Addison-Wesley, 1995\\n- Patrick Ditchen: *Shell-Skript Programmierung*, mitp, 2003\\n- Christian Mei√üer: *Bash ‚Äì Arbeiten und programmieren mit der Shell*, open source PRESS, 2011\\n\\nAngeboten in folgenden Semestern:\\nWS 2024/25, WS 2023/24, WS 2022/23, WS 2021/22, WS 2020/21\\nBETRIEBSSYSTEMEINF√úHRUNG'),\n",
       " Document(metadata={'modul': 'betriebssystemeinf√ºhrung'}, page_content='BETRIEBSSYSTEMEINF√úHRUNG\\nLiteratur:\\n- Powers, Peek, O‚ÄôReilly, Loukides: *Unix Power Tools*, O‚ÄôReilly, 2002\\n- Rosenblatt: *Learning the Korn Shell*, O‚ÄôReilly, 1995\\n- Stapelberg: *UNIX SYSTEM V.4*, Addison-Wesley, 1995\\n- Patrick Ditchen: *Shell-Skript Programmierung*, mitp, 2003\\n- Christian Mei√üer: *Bash ‚Äì Arbeiten und programmieren mit der Shell*, open source PRESS, 2011\\n\\nAngeboten in folgenden Semestern:\\nWS 2024/25, WS 2023/24, WS 2022/23, WS 2021/22, WS 2020/21\\nBETRIEBSSYSTEMEINF√úHRUNG'),\n",
       " Document(metadata={'modul': 'betriebssystemeinf√ºhrung'}, page_content='BETRIEBSSYSTEMEINF√úHRUNG\\nArbeitsaufwand:\\n- Pr√§senzzeit: 30 Veranstaltungsstunden (22,5 Zeitstunden)\\n- Gesamtumfang: 90 Stunden (bei 3 ECTS)\\n- Vor- und Nachbereitung + Pr√ºfungsvorbereitung: 67,5 Stunden\\n\\nEmpfohlene Voraussetzungen:\\nKeine\\n\\nWird empfohlen als Grundlage f√ºr:\\n- Automatisierte Softwareentwicklung (PIB-ASE)\\n- Grundlagen der Webentwicklung (PIB-WEB)\\n\\nModulverantwortung: Prof. Dr. Markus Esch\\nDozent/innen: Andreas Schaffhauser, M.Sc.\\nBETRIEBSSYSTEMEINF√úHRUNG')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
